{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Support Vector Machine - Classification (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A Support Vector Machine (SVM) performs classification by finding the hyperplane that maximizes the margin between the two classes. The vectors (cases) that define the hyperplane are the support vectors.\n",
    "\n",
    "<img src='../../../img/SVM_2.png' height=\"600\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Algorithm :__\n",
    "1. Define an optimal hyperplane: maximize margin\n",
    "2. Extend the above definition for non-linearly separable problems: have a penalty term for misclassifications.\n",
    "3. Map data to high dimensional space where it is easier to classify with linear decision surfaces: reformulate problem so that data is mapped implicitly to this space.\n",
    "\n",
    "To define an optimal hyperplane we need to maximize the width of the margin (w)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='../../../img/SVM_optimize.png' height=\"600\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We find w and b by solving the following objective function using Quadratic Programming.\n",
    "\n",
    "<img src='../../../img/SVM_optimize_2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The beauty of SVM is that if the data is linearly separable, there is a unique global minimum value. An ideal SVM analysis should produce a hyperplane that completely separates the vectors (cases) into two non-overlapping classes. \n",
    "\n",
    "However, perfect separation may not be possible, or it may result in a model with so many cases that the model does not classify correctly. In this situation SVM finds the hyperplane that maximizes the margin and minimizes the misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='../../../img/SVM_3.png' height=\"600\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The simplest way to separate two groups of data is with a straight line (1 dimension), flat plane (2 dimensions) or an N-dimensional hyperplane. However, there are situations where a nonlinear region can separate the groups more efficiently. SVM handles this by using a kernel function (nonlinear) to map the data into a different space where a hyperplane (linear) cannot be used to do the separation. It means a non-linear function is learned by a linear learning machine in a high-dimensional feature space while the capacity of the system is controlled by a parameter that does not depend on the dimensionality of the space. This is called kernel trick which means the kernel function transform the data into a higher dimensional feature space to make it possible to perform the linear separation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='../../../img/SVM_4.png' height=\"600\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='../../../img/SVM_kernel.png' height=\"600\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Code Dictionary\n",
    "code | description\n",
    "-----|------------\n",
    "`SVC()` | Support Vector Classification.\n",
    "`ListedColormap` | Define color palette to plot with.\n",
    "`.meshgrid()` | Make a pair combination of multiple array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seun.Adekunle\\AppData\\Local\\Continuum\\anaconda3\\envs\\glueviz\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Seun.Adekunle\\AppData\\Local\\Continuum\\anaconda3\\envs\\glueviz\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Seun.Adekunle\\AppData\\Local\\Continuum\\anaconda3\\envs\\glueviz\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "X = dataset.iloc[:, [2, 3]].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear', random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66,  2],\n",
       "       [ 8, 24]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "plt.figure(figsize=(12,12))\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = plt.cm.Paired)\n",
    "\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Classifier (Test set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![svm](../../../img/svm1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# In order gain more intuition about how we are splitting our grid: we'll build the plot_estimator \n",
    "\n",
    "def plot_estimator(estimator,X,y):\n",
    "    estimator.fit(X,y)\n",
    "    # ? \n",
    "    x_min, x_max =X[:,0].min() -.1, X[:,0].max() +.1\n",
    "    y_min, y_max =X[:,1].min() -.1, X[:,1].max() +.1\n",
    "    xx, yy =np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                        np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    # perform classification on our samples\n",
    "    Z= estimator.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "                        \n",
    "    # Put the result into a color plot\n",
    "    Z=Z.reshape (xx.shape)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.pcolormesh(xx,yy, Z, cmap=plt.cm.Paired)\n",
    "                        \n",
    "    # Lets plot our sample points\n",
    "    plt.scatter(X[:,0], X[:,1], c = ListedColormap(('red', 'green'))(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing our Support Vectors and C (bias)\n",
    "\n",
    "# Note that svm.LinearSVC uses the one vs. all methodology \n",
    "# where SVC implements one vs one \n",
    "\n",
    "plot_estimator(classifier,X_train, y_train)\n",
    "# and then plot actually data points\n",
    "plt.scatter(classifier.support_vectors_[:,0],classifier.support_vectors_[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![svm](../../../img/svm2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different Types of Kernels\n",
    "\n",
    "- scikit-learn provides us with several types of Kernels to work with:\n",
    "\n",
    "1) 'linear' : Linear decision boundary\n",
    "    \n",
    "    \n",
    "- Good to use when: there is a clear separation of data or  # of features is large, and # of samples are  relatively small (can prevent overfitting)\n",
    "        \n",
    "    \n",
    "2) 'poly' : Polynomial decicion boundary (adjust the order via 'order' argument)\n",
    "    \n",
    "-  The implict feature space of a polynomial kernel is equivalent to that of a polynomial regression                  (except that we do not have to worry about the combinatorial blow-up thanks due to the sparse design of the support vectors)\n",
    "    \n",
    "3) 'rbf': Radial Basis Function decision boundary ( inserts Gaussian kernel at each support vector, we can adjust the Gaussian kernel via the Gamma Feature)\n",
    "    \n",
    "    \n",
    "- Good to use when # of samples is large and features relatively small "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Given the (3) of types of kernels above, and our previous model above, build & plot 3 new models on pggm dataset using Universe_Returns_F1W and Price_USD as input and sales_growth_class as output like the logistic regression exercise \n",
    "# Which do you think is more suitable for our data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Load the pggm dataset\n",
    "pggm = pd.read_csv('http://bit.ly/PGGM_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38304 entries, 0 to 38303\n",
      "Data columns (total 18 columns):\n",
      "Identifier               38304 non-null object\n",
      "Name                     38304 non-null object\n",
      "Period                   38304 non-null object\n",
      "Period_YYYYMMDD          38304 non-null int64\n",
      "Ticker                   38304 non-null object\n",
      "Universe_Returns_F1W     38300 non-null float64\n",
      "Universe_Returns_F4W     38296 non-null float64\n",
      "Universe_Returns_F12W    38268 non-null float64\n",
      "Weight                   38304 non-null float64\n",
      "GICS_Sector              38304 non-null object\n",
      "GICS_Ind_Grp             38304 non-null object\n",
      "Market_Cap_USD           38304 non-null float64\n",
      "Price_USD                38304 non-null float64\n",
      "NTM_EP                   38246 non-null float64\n",
      "LTM_ROA                  38245 non-null float64\n",
      "BP                       38288 non-null float64\n",
      "LTM_EP                   38215 non-null float64\n",
      "5Y_Sales_Growth          38197 non-null float64\n",
      "dtypes: float64(11), int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "pggm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Remove missing data\n",
    "pggm = pggm.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pggm['sales_growth_class'] = np.where(pggm['5Y_Sales_Growth']>=0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Name</th>\n",
       "      <th>Period</th>\n",
       "      <th>Period_YYYYMMDD</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Universe_Returns_F1W</th>\n",
       "      <th>Universe_Returns_F4W</th>\n",
       "      <th>Universe_Returns_F12W</th>\n",
       "      <th>Weight</th>\n",
       "      <th>GICS_Sector</th>\n",
       "      <th>GICS_Ind_Grp</th>\n",
       "      <th>Market_Cap_USD</th>\n",
       "      <th>Price_USD</th>\n",
       "      <th>NTM_EP</th>\n",
       "      <th>LTM_ROA</th>\n",
       "      <th>BP</th>\n",
       "      <th>LTM_EP</th>\n",
       "      <th>5Y_Sales_Growth</th>\n",
       "      <th>sales_growth_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17290810</td>\n",
       "      <td>Cintas Corporation</td>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>20141231</td>\n",
       "      <td>CTAS-US</td>\n",
       "      <td>-2.517855</td>\n",
       "      <td>-0.121111</td>\n",
       "      <td>4.156041</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Commercial &amp; Professional Services</td>\n",
       "      <td>7761.120</td>\n",
       "      <td>78.44</td>\n",
       "      <td>0.044387</td>\n",
       "      <td>9.089989</td>\n",
       "      <td>0.246962</td>\n",
       "      <td>0.042708</td>\n",
       "      <td>4.718765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80589M10</td>\n",
       "      <td>SCANA Corporation</td>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>20141231</td>\n",
       "      <td>SCG-US</td>\n",
       "      <td>2.036428</td>\n",
       "      <td>6.307948</td>\n",
       "      <td>-8.426744</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>8151.001</td>\n",
       "      <td>60.40</td>\n",
       "      <td>0.061397</td>\n",
       "      <td>3.472852</td>\n",
       "      <td>0.572871</td>\n",
       "      <td>0.062748</td>\n",
       "      <td>-0.949881</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50241310</td>\n",
       "      <td>L-3 Communications Holdings Inc.</td>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>20141231</td>\n",
       "      <td>LLL-US</td>\n",
       "      <td>-0.396162</td>\n",
       "      <td>-1.283580</td>\n",
       "      <td>-0.753021</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>10883.341</td>\n",
       "      <td>126.21</td>\n",
       "      <td>0.060554</td>\n",
       "      <td>4.744629</td>\n",
       "      <td>0.570099</td>\n",
       "      <td>0.059821</td>\n",
       "      <td>-4.316938</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91301710</td>\n",
       "      <td>United Technologies Corporation</td>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>20141231</td>\n",
       "      <td>UTX-US</td>\n",
       "      <td>-1.973909</td>\n",
       "      <td>1.669562</td>\n",
       "      <td>1.815629</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>99942.990</td>\n",
       "      <td>115.00</td>\n",
       "      <td>0.062889</td>\n",
       "      <td>6.805052</td>\n",
       "      <td>0.325584</td>\n",
       "      <td>0.059088</td>\n",
       "      <td>3.083364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92939U10</td>\n",
       "      <td>Wisconsin Energy Corporation</td>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>20141231</td>\n",
       "      <td>WEC-US</td>\n",
       "      <td>1.118696</td>\n",
       "      <td>7.679176</td>\n",
       "      <td>-6.160975</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>11893.872</td>\n",
       "      <td>52.74</td>\n",
       "      <td>0.051359</td>\n",
       "      <td>4.201019</td>\n",
       "      <td>0.369798</td>\n",
       "      <td>0.050815</td>\n",
       "      <td>1.421392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Identifier                              Name      Period  Period_YYYYMMDD  \\\n",
       "0   17290810                Cintas Corporation  12/31/2014         20141231   \n",
       "1   80589M10                 SCANA Corporation  12/31/2014         20141231   \n",
       "2   50241310  L-3 Communications Holdings Inc.  12/31/2014         20141231   \n",
       "3   91301710   United Technologies Corporation  12/31/2014         20141231   \n",
       "4   92939U10      Wisconsin Energy Corporation  12/31/2014         20141231   \n",
       "\n",
       "    Ticker  Universe_Returns_F1W  Universe_Returns_F4W  Universe_Returns_F12W  \\\n",
       "0  CTAS-US             -2.517855             -0.121111               4.156041   \n",
       "1   SCG-US              2.036428              6.307948              -8.426744   \n",
       "2   LLL-US             -0.396162             -1.283580              -0.753021   \n",
       "3   UTX-US             -1.973909              1.669562               1.815629   \n",
       "4   WEC-US              1.118696              7.679176              -6.160975   \n",
       "\n",
       "     Weight  GICS_Sector                        GICS_Ind_Grp  Market_Cap_USD  \\\n",
       "0  0.000402  Industrials  Commercial & Professional Services        7761.120   \n",
       "1  0.000422    Utilities                           Utilities        8151.001   \n",
       "2  0.000563  Industrials                       Capital Goods       10883.341   \n",
       "3  0.005174  Industrials                       Capital Goods       99942.990   \n",
       "4  0.000616    Utilities                           Utilities       11893.872   \n",
       "\n",
       "   Price_USD    NTM_EP   LTM_ROA        BP    LTM_EP  5Y_Sales_Growth  \\\n",
       "0      78.44  0.044387  9.089989  0.246962  0.042708         4.718765   \n",
       "1      60.40  0.061397  3.472852  0.572871  0.062748        -0.949881   \n",
       "2     126.21  0.060554  4.744629  0.570099  0.059821        -4.316938   \n",
       "3     115.00  0.062889  6.805052  0.325584  0.059088         3.083364   \n",
       "4      52.74  0.051359  4.201019  0.369798  0.050815         1.421392   \n",
       "\n",
       "   sales_growth_class  \n",
       "0                   1  \n",
       "1                  -1  \n",
       "2                  -1  \n",
       "3                   1  \n",
       "4                   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pggm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X = pggm.iloc[:, [5,12]]\n",
    "y = pggm.iloc[:, 18] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear', random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 1692],\n",
       "       [   0, 5914]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7775440441756508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(classifier.predict(X_test), y_test.values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773602892833662\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(classifier.predict(X_train), y_train.values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "classifier = SVC(kernel='poly', random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1089,  617],\n",
       "       [3006, 2894]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5236655272153563\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(classifier.predict(X_test), y_test.values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5290927021696252\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(classifier.predict(X_train), y_train.values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(kernel='rbf', random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 1692],\n",
       "       [   0, 5914]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7775440441756508\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(classifier.predict(X_test), y_test.values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773602892833662\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(classifier.predict(X_train), y_train.values.reshape(-1, 1)))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
