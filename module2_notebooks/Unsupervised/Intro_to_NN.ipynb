{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Humans have always been fascinated by nature and today we are in the era of building intelligent machines, and there is no better inspiration than the brain. Humans are particularly blessed by evolution with a brain capable of performing the most complex tasks.\n",
    "\n",
    "Neural networks are one of the most powerful algorithms used in the field of machine learning and artificial intelligence nowadays. As the name suggests it draws inspiration from neurons in our brain and the way they are connected. Let us take a quick peek inside our brain.\n",
    "\n",
    "![Brain](../../img/brain.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Neurons are connected inside our brain as depicted in the picture above. This picture shows only 2 neurons connected to each other. In reality, thousands of neurons connect to each neuron. Let us simplify this picture to make an artificial neural network model.\n",
    "\n",
    "![Cell](../../img/cell_body.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Multiperceptron](../../img/nn_1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Perceptron\n",
    "\n",
    "Perceptron is considered the smallest unit of neural networks, it acts as a linear classifier.Let’s look at a very small classification example. Let us try to build a machine which identifies whether an object is a cricket ball or not.\n",
    "\n",
    "![Cricket](../../img/cricket.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us arbitrarily choose some properties of this ball.\n",
    "\n",
    "1. It is Red, we will call this property R of the ball\n",
    "2. It is spherical, we will call this property S of the ball\n",
    "\n",
    "![Table](../../img/properties.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Depending on the arbitrarily chosen properties, also known as features, we will classify the object as a cricket ball or not. The above table tells us that if a ball is red and spherical, it is a cricket ball, in all other cases, it is not. Let’s see how to do this with a neural network.\n",
    "\n",
    "To build our super tiny brain which can identify a cricket ball we will take a neuron which just adds up the inputs and outputs the sum.\n",
    "\n",
    "![NN](../../img/nn_2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Breaking down the above figure; $b, R$ and $S$ are input neurons or simply the inputs to the network, $w0, w1$ and $w2$ are the strengths of connections to the middle neuron which sums up the inputs to it. $b$ here is a constant which is called bias. \n",
    "\n",
    "The last step which is the rightmost neuron is just a function called activation function which outputs 1 if the input to it is positive and 0 if the input it negative. Mathematically it looks like:\n",
    "\n",
    "![form](../../img/formula_1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "if this SUM > 0, Output = 1 or Yes and SUM < 0, Output = 0 or No\n",
    "\n",
    "Let us look at how this helps in classifying our cricket ball. We choose some arbitrary numbers for our connection strengths $w$ and our constant $b$. This is done with a mathematical technique called gradient descent and it is the act of getting this that is called training a neural network. \n",
    "\n",
    "For now let’s just assume we got these numbers from somewhere\n",
    "\n",
    "![form2](../../img/formula_2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us fit these values\n",
    "\n",
    "Case 1: When the object is neither a sphere (S=0) nor red (R=0)\n",
    "\n",
    "![rugby](../../img/rugby.jpeg)\n",
    "\n",
    "![form3](../../img/formula_3.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "he SUM<0 which means the output is 0 or No. Our perceptron says that this is not a cricket ball.\n",
    "\n",
    "Case 2: When the object is a sphere (S=1) but not red (R=0)\n",
    "\n",
    "![tennis](../../img/tennis.jpeg)\n",
    "\n",
    "![form4](../../img/formula_4.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The SUM<0 which means the output is 0 or No, not a cricket ball\n",
    "\n",
    "Case:3 When the object is not a sphere (S=0) but red (R=1)\n",
    "\n",
    "![strawberry](../../img/strawberry.jpeg)\n",
    "\n",
    "![form5](../../img/formula_5.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The SUM<0 which means the output is 0 or No, not a cricket ball\n",
    "\n",
    "Case 4: When the object is a sphere (S=1) and red (R=1)\n",
    "\n",
    "![cricket2](../../img/cricket_2.jpeg)\n",
    "\n",
    "![form6](../../img/formula6.jpeg)\n",
    "\n",
    "The SUM>0 which means the output is 1. Et Voila! Our perceptron says it is a cricket ball.\n",
    "\n",
    "This is the most rudimentary idea behind a neural network even though oversimplified. We connect lot of these perceptrons in a particular manner and what we get is a neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Code Dictionary\n",
    "code | description\n",
    "-----|------------\n",
    "`sklearn.neural_network.MLPClassifier` | neural network multi-layer perceptron classifier of scikit-learn.\n",
    "`sklearn.neural_network.MLPRegressor` |  neural network multi-layer perceptron regression model of scikit-learn.\n",
    "`classification_report` | provides precsion, recall and f1scores of a classification model.\n",
    "`.value_counts()` | provides counts of unique values for a feature.\n",
    "`.pairplot()` | Plot pairwise relationships of numerical features in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Location of dataset\n",
    "url = 'http://bit.ly/PGGM_dataset'\n",
    "\n",
    "# Read dataset to pandas dataframe\n",
    "irisdata = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To see what this dataset actually looks like, execute the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Data Exploration\n",
    "We always want to visualize and understand our data first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 38304, Features: 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Name</th>\n",
       "      <th>Period</th>\n",
       "      <th>Period_YYYYMMDD</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Universe_Returns_F1W</th>\n",
       "      <th>Universe_Returns_F4W</th>\n",
       "      <th>Universe_Returns_F12W</th>\n",
       "      <th>Weight</th>\n",
       "      <th>GICS_Sector</th>\n",
       "      <th>GICS_Ind_Grp</th>\n",
       "      <th>Market_Cap_USD</th>\n",
       "      <th>Price_USD</th>\n",
       "      <th>NTM_EP</th>\n",
       "      <th>LTM_ROA</th>\n",
       "      <th>BP</th>\n",
       "      <th>LTM_EP</th>\n",
       "      <th>5Y_Sales_Growth</th>\n",
       "      <th>cat_sales_growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17290810</td>\n",
       "      <td>Cintas Corporation</td>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>20141231</td>\n",
       "      <td>CTAS-US</td>\n",
       "      <td>-2.517855</td>\n",
       "      <td>-0.121111</td>\n",
       "      <td>4.156041</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Commercial &amp; Professional Services</td>\n",
       "      <td>7761.120</td>\n",
       "      <td>78.44</td>\n",
       "      <td>0.044387</td>\n",
       "      <td>9.089989</td>\n",
       "      <td>0.246962</td>\n",
       "      <td>0.042708</td>\n",
       "      <td>4.718765</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80589M10</td>\n",
       "      <td>SCANA Corporation</td>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>20141231</td>\n",
       "      <td>SCG-US</td>\n",
       "      <td>2.036428</td>\n",
       "      <td>6.307948</td>\n",
       "      <td>-8.426744</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>8151.001</td>\n",
       "      <td>60.40</td>\n",
       "      <td>0.061397</td>\n",
       "      <td>3.472852</td>\n",
       "      <td>0.572871</td>\n",
       "      <td>0.062748</td>\n",
       "      <td>-0.949881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50241310</td>\n",
       "      <td>L-3 Communications Holdings Inc.</td>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>20141231</td>\n",
       "      <td>LLL-US</td>\n",
       "      <td>-0.396162</td>\n",
       "      <td>-1.283580</td>\n",
       "      <td>-0.753021</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>10883.341</td>\n",
       "      <td>126.21</td>\n",
       "      <td>0.060554</td>\n",
       "      <td>4.744629</td>\n",
       "      <td>0.570099</td>\n",
       "      <td>0.059821</td>\n",
       "      <td>-4.316938</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91301710</td>\n",
       "      <td>United Technologies Corporation</td>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>20141231</td>\n",
       "      <td>UTX-US</td>\n",
       "      <td>-1.973909</td>\n",
       "      <td>1.669562</td>\n",
       "      <td>1.815629</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>99942.990</td>\n",
       "      <td>115.00</td>\n",
       "      <td>0.062889</td>\n",
       "      <td>6.805052</td>\n",
       "      <td>0.325584</td>\n",
       "      <td>0.059088</td>\n",
       "      <td>3.083364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92939U10</td>\n",
       "      <td>Wisconsin Energy Corporation</td>\n",
       "      <td>12/31/2014</td>\n",
       "      <td>20141231</td>\n",
       "      <td>WEC-US</td>\n",
       "      <td>1.118696</td>\n",
       "      <td>7.679176</td>\n",
       "      <td>-6.160975</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>11893.872</td>\n",
       "      <td>52.74</td>\n",
       "      <td>0.051359</td>\n",
       "      <td>4.201019</td>\n",
       "      <td>0.369798</td>\n",
       "      <td>0.050815</td>\n",
       "      <td>1.421392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Identifier                              Name      Period  Period_YYYYMMDD  \\\n",
       "0   17290810                Cintas Corporation  12/31/2014         20141231   \n",
       "1   80589M10                 SCANA Corporation  12/31/2014         20141231   \n",
       "2   50241310  L-3 Communications Holdings Inc.  12/31/2014         20141231   \n",
       "3   91301710   United Technologies Corporation  12/31/2014         20141231   \n",
       "4   92939U10      Wisconsin Energy Corporation  12/31/2014         20141231   \n",
       "\n",
       "    Ticker  Universe_Returns_F1W  Universe_Returns_F4W  Universe_Returns_F12W  \\\n",
       "0  CTAS-US             -2.517855             -0.121111               4.156041   \n",
       "1   SCG-US              2.036428              6.307948              -8.426744   \n",
       "2   LLL-US             -0.396162             -1.283580              -0.753021   \n",
       "3   UTX-US             -1.973909              1.669562               1.815629   \n",
       "4   WEC-US              1.118696              7.679176              -6.160975   \n",
       "\n",
       "     Weight  GICS_Sector                        GICS_Ind_Grp  Market_Cap_USD  \\\n",
       "0  0.000402  Industrials  Commercial & Professional Services        7761.120   \n",
       "1  0.000422    Utilities                           Utilities        8151.001   \n",
       "2  0.000563  Industrials                       Capital Goods       10883.341   \n",
       "3  0.005174  Industrials                       Capital Goods       99942.990   \n",
       "4  0.000616    Utilities                           Utilities       11893.872   \n",
       "\n",
       "   Price_USD    NTM_EP   LTM_ROA        BP    LTM_EP  5Y_Sales_Growth  \\\n",
       "0      78.44  0.044387  9.089989  0.246962  0.042708         4.718765   \n",
       "1      60.40  0.061397  3.472852  0.572871  0.062748        -0.949881   \n",
       "2     126.21  0.060554  4.744629  0.570099  0.059821        -4.316938   \n",
       "3     115.00  0.062889  6.805052  0.325584  0.059088         3.083364   \n",
       "4      52.74  0.051359  4.201019  0.369798  0.050815         1.421392   \n",
       "\n",
       "   cat_sales_growth  \n",
       "0                -1  \n",
       "1                 1  \n",
       "2                -1  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Samples: {}, Features: {}\".format(*irisdata.shape))\n",
    "irisdata['cat_sales_growth'] = np.where(irisdata['Universe_Returns_F4W']>0, 1, -1)\n",
    "irisdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wow! 38k samples. Good since we want over 10K samples! Also we have about 18 features so it seems like the curse of dimensionality may be an issue. Next, lets make a pairplot to see that there are a couple of features which will give a large indication of how to classify our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seun.Adekunle\\AppData\\Local\\Continuum\\anaconda3\\envs\\glueviz\\lib\\site-packages\\statsmodels\\nonparametric\\kde.py:448: RuntimeWarning: invalid value encountered in greater\n",
      "  X = X[np.logical_and(X > clip[0], X < clip[1])] # won't work for two columns.\n",
      "C:\\Users\\Seun.Adekunle\\AppData\\Local\\Continuum\\anaconda3\\envs\\glueviz\\lib\\site-packages\\statsmodels\\nonparametric\\kde.py:448: RuntimeWarning: invalid value encountered in less\n",
      "  X = X[np.logical_and(X > clip[0], X < clip[1])] # won't work for two columns.\n",
      "C:\\Users\\Seun.Adekunle\\AppData\\Local\\Continuum\\anaconda3\\envs\\glueviz\\lib\\site-packages\\statsmodels\\nonparametric\\kde.py:488: RuntimeWarning: invalid value encountered in true_divide\n",
      "  binned = fast_linbin(X, a, b, gridsize) / (delta * nobs)\n",
      "C:\\Users\\Seun.Adekunle\\AppData\\Local\\Continuum\\anaconda3\\envs\\glueviz\\lib\\site-packages\\statsmodels\\nonparametric\\kdetools.py:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  FAC1 = 2*(np.pi*bw/RANGE)**2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x240db7c0ba8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "g = sns.pairplot(irisdata, hue=\"cat_sales_growth\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![pairplot](../../img/pairplot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Remove missing data\n",
    "irisdata = irisdata.dropna()\n",
    "\n",
    "# Assign data from fifth column to 8th variable Universe_Returns_F1W to Weight\n",
    "X = irisdata.iloc[:, 5:9]\n",
    "\n",
    "# Assign data from our new categorical columns to y variable\n",
    "y = irisdata.iloc[:, 18] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1\n",
       "1    1\n",
       "2   -1\n",
       "3    1\n",
       "4    1\n",
       "Name: cat_sales_growth, dtype: int32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "first let's see how many unique values we have in our y series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    19837\n",
       "-1    18189\n",
       "Name: cat_sales_growth, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training and Predictions\n",
    "And now it's finally time to do what you have been waiting for, train a neural network that can actually make predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.53773880\n",
      "Validation score: 0.773997\n",
      "Iteration 2, loss = 0.53775811\n",
      "Validation score: 0.773997\n",
      "Iteration 3, loss = 0.53789253\n",
      "Validation score: 0.773997\n",
      "Iteration 4, loss = 0.53744243\n",
      "Validation score: 0.773997\n",
      "Iteration 5, loss = 0.53757204\n",
      "Validation score: 0.773997\n",
      "Iteration 6, loss = 0.53782725\n",
      "Validation score: 0.773997\n",
      "Iteration 7, loss = 0.53815160\n",
      "Validation score: 0.773997\n",
      "Iteration 8, loss = 0.53642282\n",
      "Validation score: 0.773997\n",
      "Iteration 9, loss = 0.53676091\n",
      "Validation score: 0.773997\n",
      "Iteration 10, loss = 0.53654978\n",
      "Validation score: 0.773997\n",
      "Iteration 11, loss = 0.53643155\n",
      "Validation score: 0.773997\n",
      "Iteration 12, loss = 0.53674682\n",
      "Validation score: 0.773997\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.060000\n",
      "Iteration 13, loss = 0.53411285\n",
      "Validation score: 0.773997\n",
      "Iteration 14, loss = 0.53412695\n",
      "Validation score: 0.773997\n",
      "Iteration 15, loss = 0.53402467\n",
      "Validation score: 0.773997\n",
      "Iteration 16, loss = 0.53412661\n",
      "Validation score: 0.773997\n",
      "Iteration 17, loss = 0.53431159\n",
      "Validation score: 0.773997\n",
      "Iteration 18, loss = 0.53379182\n",
      "Validation score: 0.773997\n",
      "Iteration 19, loss = 0.53421163\n",
      "Validation score: 0.773997\n",
      "Iteration 20, loss = 0.53406291\n",
      "Validation score: 0.773997\n",
      "Iteration 21, loss = 0.53415442\n",
      "Validation score: 0.773997\n",
      "Iteration 22, loss = 0.53410583\n",
      "Validation score: 0.773997\n",
      "Iteration 23, loss = 0.53402685\n",
      "Validation score: 0.773997\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.012000\n",
      "Iteration 24, loss = 0.53326966\n",
      "Validation score: 0.773997\n",
      "Iteration 25, loss = 0.53338752\n",
      "Validation score: 0.773997\n",
      "Iteration 26, loss = 0.53330203\n",
      "Validation score: 0.773997\n",
      "Iteration 27, loss = 0.53335491\n",
      "Validation score: 0.773997\n",
      "Iteration 28, loss = 0.53330767\n",
      "Validation score: 0.773997\n",
      "Iteration 29, loss = 0.53330650\n",
      "Validation score: 0.773997\n",
      "Iteration 30, loss = 0.53328348\n",
      "Validation score: 0.773997\n",
      "Iteration 31, loss = 0.53323353\n",
      "Validation score: 0.773997\n",
      "Iteration 32, loss = 0.53336896\n",
      "Validation score: 0.773997\n",
      "Iteration 33, loss = 0.53322716\n",
      "Validation score: 0.773997\n",
      "Iteration 34, loss = 0.53335252\n",
      "Validation score: 0.773997\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.002400\n",
      "Iteration 35, loss = 0.53316098\n",
      "Validation score: 0.773997\n",
      "Iteration 36, loss = 0.53311791\n",
      "Validation score: 0.773997\n",
      "Iteration 37, loss = 0.53316985\n",
      "Validation score: 0.773997\n",
      "Iteration 38, loss = 0.53315063\n",
      "Validation score: 0.773997\n",
      "Iteration 39, loss = 0.53317321\n",
      "Validation score: 0.773997\n",
      "Iteration 40, loss = 0.53316303\n",
      "Validation score: 0.773997\n",
      "Iteration 41, loss = 0.53315770\n",
      "Validation score: 0.773997\n",
      "Iteration 42, loss = 0.53315566\n",
      "Validation score: 0.773997\n",
      "Iteration 43, loss = 0.53311719\n",
      "Validation score: 0.773997\n",
      "Iteration 44, loss = 0.53315964\n",
      "Validation score: 0.773997\n",
      "Iteration 45, loss = 0.53316013\n",
      "Validation score: 0.773997\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000480\n",
      "Iteration 46, loss = 0.53311571\n",
      "Validation score: 0.773997\n",
      "Iteration 47, loss = 0.53311675\n",
      "Validation score: 0.773997\n",
      "Iteration 48, loss = 0.53311131\n",
      "Validation score: 0.773997\n",
      "Iteration 49, loss = 0.53311291\n",
      "Validation score: 0.773997\n",
      "Iteration 50, loss = 0.53311404\n",
      "Validation score: 0.773997\n",
      "Iteration 51, loss = 0.53311547\n",
      "Validation score: 0.773997\n",
      "Iteration 52, loss = 0.53311385\n",
      "Validation score: 0.773997\n",
      "Iteration 53, loss = 0.53311214\n",
      "Validation score: 0.773997\n",
      "Iteration 54, loss = 0.53311483\n",
      "Validation score: 0.773997\n",
      "Iteration 55, loss = 0.53311301\n",
      "Validation score: 0.773997\n",
      "Iteration 56, loss = 0.53311562\n",
      "Validation score: 0.773997\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000096\n",
      "Iteration 57, loss = 0.53310396\n",
      "Validation score: 0.773997\n",
      "Iteration 58, loss = 0.53310451\n",
      "Validation score: 0.773997\n",
      "Iteration 59, loss = 0.53310424\n",
      "Validation score: 0.773997\n",
      "Iteration 60, loss = 0.53310376\n",
      "Validation score: 0.773997\n",
      "Iteration 61, loss = 0.53310435\n",
      "Validation score: 0.773997\n",
      "Iteration 62, loss = 0.53310349\n",
      "Validation score: 0.773997\n",
      "Iteration 63, loss = 0.53310391\n",
      "Validation score: 0.773997\n",
      "Iteration 64, loss = 0.53310423\n",
      "Validation score: 0.773997\n",
      "Iteration 65, loss = 0.53310432\n",
      "Validation score: 0.773997\n",
      "Iteration 66, loss = 0.53310362\n",
      "Validation score: 0.773997\n",
      "Iteration 67, loss = 0.53310354\n",
      "Validation score: 0.773997\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000019\n",
      "Iteration 68, loss = 0.53310169\n",
      "Validation score: 0.773997\n",
      "Iteration 69, loss = 0.53310165\n",
      "Validation score: 0.773997\n",
      "Iteration 70, loss = 0.53310169\n",
      "Validation score: 0.773997\n",
      "Iteration 71, loss = 0.53310169\n",
      "Validation score: 0.773997\n",
      "Iteration 72, loss = 0.53310170\n",
      "Validation score: 0.773997\n",
      "Iteration 73, loss = 0.53310158\n",
      "Validation score: 0.773997\n",
      "Iteration 74, loss = 0.53310176\n",
      "Validation score: 0.773997\n",
      "Iteration 75, loss = 0.53310159\n",
      "Validation score: 0.773997\n",
      "Iteration 76, loss = 0.53310161\n",
      "Validation score: 0.773997\n",
      "Iteration 77, loss = 0.53310157\n",
      "Validation score: 0.773997\n",
      "Iteration 78, loss = 0.53310163\n",
      "Validation score: 0.773997\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000004\n",
      "Iteration 79, loss = 0.53310118\n",
      "Validation score: 0.773997\n",
      "Iteration 80, loss = 0.53310117\n",
      "Validation score: 0.773997\n",
      "Iteration 81, loss = 0.53310118\n",
      "Validation score: 0.773997\n",
      "Iteration 82, loss = 0.53310120\n",
      "Validation score: 0.773997\n",
      "Iteration 83, loss = 0.53310120\n",
      "Validation score: 0.773997\n",
      "Iteration 84, loss = 0.53310118\n",
      "Validation score: 0.773997\n",
      "Iteration 85, loss = 0.53310119\n",
      "Validation score: 0.773997\n",
      "Iteration 86, loss = 0.53310120\n",
      "Validation score: 0.773997\n",
      "Iteration 87, loss = 0.53310117\n",
      "Validation score: 0.773997\n",
      "Iteration 88, loss = 0.53310119\n",
      "Validation score: 0.773997\n",
      "Iteration 89, loss = 0.53310118\n",
      "Validation score: 0.773997\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 90, loss = 0.53310110\n",
      "Validation score: 0.773997\n",
      "Iteration 91, loss = 0.53310110\n",
      "Validation score: 0.773997\n",
      "Iteration 92, loss = 0.53310110\n",
      "Validation score: 0.773997\n",
      "Iteration 93, loss = 0.53310110\n",
      "Validation score: 0.773997\n",
      "Iteration 94, loss = 0.53310110\n",
      "Validation score: 0.773997\n",
      "Iteration 95, loss = 0.53310110\n",
      "Validation score: 0.773997\n",
      "Iteration 96, loss = 0.53310110\n",
      "Validation score: 0.773997\n",
      "Iteration 97, loss = 0.53310110\n",
      "Validation score: 0.773997\n",
      "Iteration 98, loss = 0.53310110\n",
      "Validation score: 0.773997\n",
      "Iteration 99, loss = 0.53310110\n",
      "Validation score: 0.773997\n",
      "Iteration 100, loss = 0.53310110\n",
      "Validation score: 0.773997\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size=32, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50, 3), learning_rate='adaptive',\n",
       "       learning_rate_init=0.3, max_iter=100, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.2, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(50,3),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    batch_size=32,\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.3,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.2,\n",
    "    verbose=10,\n",
    "    random_state=42,\n",
    "    max_iter=100\n",
    ")\n",
    "# from plot_learning_curve import plot_learning_curve\n",
    "clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Yes, with Scikit-Learn, you can create neural network with these three lines of code, which all handles much of the leg work for you. Let's see what is happening in the above script. The first step is to import the MLPClassifier class from the sklearn.neural_network library. In the second line, this class is initialized with two parameters.\n",
    "\n",
    "The parameter, hidden_layer_sizes, is used to set the size of the hidden layers. In our script we will create three layers of 50 nodes each. There is no standard formula for choosing the number of layers and nodes for a neural network and it varies quite a bit depending on the problem at hand. The best way is to try different combinations and see what works best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1701\n",
      "           1       0.78      1.00      0.87      5905\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      7606\n",
      "   macro avg       0.39      0.50      0.44      7606\n",
      "weighted avg       0.60      0.78      0.68      7606\n",
      "\n",
      "Test set score: 0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seun.Adekunle\\AppData\\Local\\Continuum\\anaconda3\\envs\\glueviz\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(\"Test set score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seun.Adekunle\\AppData\\Local\\Continuum\\anaconda3\\envs\\glueviz\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,predictions)\n",
    "labels = ['negative growth', 'positive growth']\n",
    "figure = sns.heatmap(cm / sum(cm), cmap=\"YlGnBu\", annot=True, fmt=\".1%\", xticklabels=labels, yticklabels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A confusion matrix can be useful to seeing where our model is struggling. We want 100%s on the diagonal. In this case, it looks like our model can only predict positive growth. This can be due to the class imbalance of sales growth and we may want to do better feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='../../img/download.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='../../img/download1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='../../img/download2.png'>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
